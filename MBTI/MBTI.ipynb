{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myers-Briggs Type Indicator demo\n",
    "\n",
    "Intructions: Execute the two cells below to load the functions and then enter text in space provided to estimate the MBTI personality\n",
    "\n",
    "**Note: This notebook requires SpaCy and IPython widgets to be installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System:\n",
      "    python: 3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]\n",
      "executable: c:\\python39\\python.exe\n",
      "   machine: Windows-10-10.0.19042-SP0\n",
      "\n",
      "Python dependencies:\n",
      "          pip: 21.1.2\n",
      "   setuptools: 56.0.0\n",
      "      sklearn: 0.24.2\n",
      "        numpy: 1.21.0\n",
      "        scipy: 1.7.0\n",
      "       Cython: 0.29.23\n",
      "       pandas: 1.2.4\n",
      "   matplotlib: 3.4.1\n",
      "       joblib: 1.0.1\n",
      "threadpoolctl: 2.1.0\n",
      "\n",
      "Built with OpenMP: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:\\\\sanchit\\\\Downloads\\\\datascience-master\\\\datascience-master\\\\PersonalityDetection\\\\MBTI_demo\\\\demo',\n",
       " 'c:\\\\python39\\\\python39.zip',\n",
       " 'c:\\\\python39\\\\DLLs',\n",
       " 'c:\\\\python39\\\\lib',\n",
       " 'c:\\\\python39',\n",
       " '',\n",
       " 'C:\\\\Users\\\\sanch\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages',\n",
       " 'c:\\\\python39\\\\lib\\\\site-packages',\n",
       " 'c:\\\\python39\\\\lib\\\\site-packages\\\\win32',\n",
       " 'c:\\\\python39\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'c:\\\\python39\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\sanch\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\sanch\\\\.ipython']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.show_versions()\n",
    "import sys\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanch\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.21.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sanch\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator TfidfTransformer from version 0.21.2 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.linear_model.logistic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cbd6d4c55e7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m# loading the pickle files with the classifiers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./pickle files/LR_clf_IE_kaggle.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mlr_ie\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./pickle files/LR_clf_JP_kaggle.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mlr_jp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.linear_model.logistic'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def tokeniser(sentence):\n",
    " \n",
    "    # Remove ||| from kaggle dataset\n",
    "    sentence = re.sub(\"[]|||[]\", \" \", sentence)\n",
    "\n",
    "    # remove reddit subreddit urls\n",
    "    sentence = re.sub(\"/r/[0-9A-Za-z]\", \"\", sentence)\n",
    "\n",
    "    # remove MBTI types\n",
    "    MBTI_types = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "              'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ',\n",
    "              'MBTI']\n",
    "    MBTI_types = [ti.lower() for ti in MBTI_types] + [ti.lower() + 's' for ti in MBTI_types]\n",
    "\n",
    "    tokens = nlp(sentence)\n",
    "\n",
    "    tokens = [ti for ti in tokens if ti.lower_ not in STOP_WORDS]\n",
    "    tokens = [ti for ti in tokens if not ti.is_space]\n",
    "    tokens = [ti for ti in tokens if not ti.is_punct]\n",
    "    tokens = [ti for ti in tokens if not ti.like_num]\n",
    "    tokens = [ti for ti in tokens if not ti.like_url]\n",
    "    tokens = [ti for ti in tokens if not ti.like_email]\n",
    "    tokens = [ti for ti in tokens if ti.lower_ not in MBTI_types]\n",
    "\n",
    "\n",
    "    # lemmatize\n",
    "    tokens = [ti.lemma_ for ti in tokens if ti.lemma_ not in STOP_WORDS]\n",
    "    tokens = [ti for ti in tokens if len(ti) > 1]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "dummy_fn = lambda x:x\n",
    "\n",
    "\n",
    "with open('./pickle files/cv.pickle', 'rb') as f:\n",
    "    cv = pickle.load(f)\n",
    "    \n",
    "with open('./pickle files/idf_transformer.pickle', 'rb') as f:\n",
    "    idf_transformer = pickle.load(f)\n",
    "    \n",
    "# loading the pickle files with the classifiers\n",
    "with open('./pickle files/LR_clf_IE_kaggle.pickle', 'rb') as f:\n",
    "    lr_ie = pickle.load(f)\n",
    "with open('./pickle files/LR_clf_JP_kaggle.pickle', 'rb') as f:\n",
    "    lr_jp = pickle.load(f)\n",
    "with open('./pickle files/LR_clf_NS_kaggle.pickle', 'rb') as f:\n",
    "    lr_ns = pickle.load(f)\n",
    "with open('./pickle files/LR_clf_TF_kaggle.pickle', 'rb') as f:\n",
    "    lr_tf = pickle.load(f)\n",
    "\n",
    "\n",
    "def eval_string(my_post, show_graph=False):\n",
    "    c = cv.transform([tokeniser(my_post)])\n",
    "    x = idf_transformer.transform(c)\n",
    "    \n",
    "    ie = lr_ie.predict_proba(x).flatten()\n",
    "    ns = lr_ns.predict_proba(x).flatten()\n",
    "    tf = lr_tf.predict_proba(x).flatten()\n",
    "    jp = lr_jp.predict_proba(x).flatten()\n",
    "    \n",
    "    probs = np.vstack([ie, ns, tf, jp])\n",
    "    \n",
    "    names = [\"Introversion - Extroversion\", \n",
    "             \"Intuiting - Sensing\", \n",
    "             \"Thinking - Feeling\", \n",
    "             \"Judging - Perceiving\"]\n",
    "    \n",
    "    for i, dim in enumerate(names):\n",
    "        print(f\"{dim:28s}: {probs[i,1]:.3f} - {probs[i, 0]:.3f}\")\n",
    "        \n",
    "    if show_graph:\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.gca()\n",
    "        \n",
    "        xlabels = [\"Introversion (I)\", \"Intuiting (N)\", \"Thinking (T)\", \"Judging (J)\"]\n",
    "        ax.barh(xlabels, [1, 1, 1, 1])\n",
    "        ax.barh(xlabels, [ie[1], ns[1], tf[1], jp[1]])\n",
    "        \n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_xlabel(\"Propensity\")\n",
    "        \n",
    "        plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type in some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(eval_string, my_post=widgets.Textarea( value='', \n",
    "                                               placeholder='Enter in some text', \n",
    "                                               description='Input:',\n",
    "                                               disabled=False)\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
